{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Question-2. Part-1 Sequence to Sequence Model for Translation (4pt)"
      ],
      "metadata": {
        "id": "JWODgUEAzoRU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8WGZY2P1Yf_"
      },
      "source": [
        "###Loading data files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xf9iolIuwcJx"
      },
      "outputs": [],
      "source": [
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "from __future__ import print_function, division\n",
        "from torch.optim import lr_scheduler\n",
        "%matplotlib inline\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from google.colab import drive\n",
        "import heapq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wT5K3uQCw4s-",
        "outputId": "f048d539-f01a-47b7-be70-774d0e955572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/IDS576_Assignment_3\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/IDS576_Assignment_3\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP3ShShZeANi",
        "outputId": "81ccbd2b-ee76-4c72-a94c-979f80b09da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtZYf9UIxAeX"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import re\n",
        "import random\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import unicodedata\n",
        "import string\n",
        "import torch.nn as nn\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQBX7kkZxMgV"
      },
      "outputs": [],
      "source": [
        "cuda = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGVHdoR9xUfs"
      },
      "outputs": [],
      "source": [
        "SOS_tkn = 0\n",
        "EOS_tkn = 1\n",
        "class Lang:\n",
        "  def __init__(self, name):\n",
        "      self.name = name\n",
        "      self.wordToIndex = {}\n",
        "      self.wordToCount = {}\n",
        "      self.indexToword = {0: \"SOS\", 1: \"EOS\"}\n",
        "      self.min_words = 2\n",
        "\n",
        "  def addSentence(self, sentence):\n",
        "    for word in sentence.split(' '):\n",
        "      self.addWord(word)\n",
        "\n",
        "  def addWord(self, word):\n",
        "    if word not in self.wordToIndex:\n",
        "      self.wordToIndex[word] = self.min_words\n",
        "      self.wordToCount[word] = 1\n",
        "      self.indexToword[self.min_words] = word\n",
        "      self.min_words += 1\n",
        "    else:\n",
        "      self.wordToCount[word] += 1\n",
        "\n",
        "def unicodeToAscii(ns):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', ns)\n",
        "    if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def stringNormalize(ns):\n",
        "  ns = unicodeToAscii(ns.lower().strip())\n",
        "  ns = re.sub(r\"([.!?])\", r\" \\1\", ns)\n",
        "  ns = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", ns)\n",
        "  return ns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxqGR0EGxx3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3b8bad9-ebc6-4475-c73a-03d1542df94e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading Data:\n",
            "Read 118964 sentence pairs\n",
            "Trimmed to 90751 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "spa 20221\n",
            "eng 10763\n"
          ]
        }
      ],
      "source": [
        "def readLang(lng_1, lng_2, reverse=False):\n",
        "    print(\"Reading Data:\")\n",
        "\n",
        "    lines = open('/content/drive/MyDrive/IDS576_Assignment_3/spa-eng/spa.txt' , encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    pairs = [[stringNormalize(s) for s in l.split('\\t')] for l in lines]\n",
        "    l=[]\n",
        "    for s in pairs:\n",
        "      l.append(s[0:2])\n",
        "    pairs = l\n",
        "    pairs\n",
        "\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        inp_lang, op_lang = Lang(lng_2), Lang(lng_1)\n",
        "    else:\n",
        "        inp_lang, op_lang = Lang(lng_1), Lang(lng_2)\n",
        "\n",
        "    return inp_lang, op_lang, pairs\n",
        "\n",
        "MX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "  \"i am \", \"i m \",\n",
        "  \"he is\", \"he s \",\n",
        "  \"she is\", \"she s \",\n",
        "  \"you are\", \"you re \",\n",
        "  \"we are\", \"we re \",\n",
        "  \"they are\", \"they re \"\n",
        ")\n",
        "def filterPair(p):\n",
        "  return len(p[0].split(' ')) < MX_LENGTH and len(p[1].split(' ')) < MX_LENGTH\n",
        "\n",
        "def filterPairs(pairs):\n",
        "  return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "def prepareData(lng_1, lng_2, reverse=False):\n",
        "    inp_lang, op_lang, pairs = readLang(lng_1, lng_2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        inp_lang.addSentence(pair[0])\n",
        "        op_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(inp_lang.name, inp_lang.min_words)\n",
        "    print(op_lang.name, op_lang.min_words)\n",
        "    return inp_lang, op_lang, pairs\n",
        "\n",
        "inp_lang, op_lang, pairs = prepareData('eng', 'spa', True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnrG47CH1f3l"
      },
      "source": [
        "### Encoder and Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YFld1yjybna"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self, input_size, hdnSize):\n",
        "    super(EncoderRNN, self).__init__()\n",
        "    self.hdnSize = hdnSize\n",
        "\n",
        "    self.embedding = nn.Embedding(input_size, hdnSize)\n",
        "    self.gru = nn.GRU(hdnSize, hdnSize)\n",
        "\n",
        "  def forward(self, input, hidden):\n",
        "    embdInp = self.embedding(input).view(1, 1, -1)\n",
        "    output = embdInp\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "    return output, hidden\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, 1, self.hdnSize, device=cuda)\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "  def __init__(self, hdnSize, output_size):\n",
        "    super(DecoderRNN, self).__init__()\n",
        "    self.hdnSize = hdnSize\n",
        "    self.embedding = nn.Embedding(output_size, hdnSize)\n",
        "    self.gru = nn.GRU(hdnSize, hdnSize)\n",
        "    self.out = nn.Linear(hdnSize, output_size)\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "def forward(self, input, hidden):\n",
        "    output = self.embedding(input).view(1, 1, -1)\n",
        "    output = F.relu(output)\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "    output = self.softmax(self.out(output[0]))\n",
        "    return output, hidden\n",
        "def initHidden(self):\n",
        "    return torch.zeros(1, 1, self.hdnSize, device=cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcUGZhmPyoCd"
      },
      "outputs": [],
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "  def __init__(self, hdnSize, output_size, dropout_p=0.1, max_length=MX_LENGTH):\n",
        "    super(AttnDecoderRNN, self).__init__()\n",
        "    self.hdnSize = hdnSize\n",
        "    self.output_size = output_size\n",
        "    self.dropout_p = dropout_p\n",
        "    self.max_length = max_length\n",
        "\n",
        "    self.embedding = nn.Embedding(self.output_size, self.hdnSize)\n",
        "    self.attn = nn.Linear(self.hdnSize * 2, self.max_length)\n",
        "    self.attn_combine = nn.Linear(self.hdnSize * 2, self.hdnSize)\n",
        "    self.dropout = nn.Dropout(self.dropout_p)\n",
        "    self.gru = nn.GRU(self.hdnSize, self.hdnSize)\n",
        "    self.out = nn.Linear(self.hdnSize, self.output_size)\n",
        "\n",
        "  def forward(self, input, hidden, encoderOutputs):\n",
        "      embdInp = self.embedding(input).view(1, 1, -1)\n",
        "      embdInp = self.dropout(embdInp)\n",
        "\n",
        "      attn_weights = F.softmax(\n",
        "        self.attn(torch.cat((embdInp[0], hidden[0]), 1)), dim=1)\n",
        "      attnApplied = torch.bmm(attn_weights.unsqueeze(0), encoderOutputs.unsqueeze(0))\n",
        "\n",
        "      output = torch.cat((embdInp[0], attnApplied[0]), 1)\n",
        "      output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "      output = F.relu(output)\n",
        "      output, hidden = self.gru(output, hidden)\n",
        "\n",
        "      output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "      return output, hidden, attn_weights\n",
        "\n",
        "  def initHidden(self):\n",
        "      return torch.zeros(1, 1, self.hdnSize, device=cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xr-pWs6y3kM"
      },
      "outputs": [],
      "source": [
        "def indexesfSentence(lang, sentence):\n",
        "  return [lang.wordToIndex[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorfSentence(lang, sentence):\n",
        "  indexes = indexesfSentence(lang, sentence)\n",
        "  indexes.append(EOS_tkn)\n",
        "  return torch.tensor(indexes, dtype=torch.long, device=cuda).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "  inpTensor, target_tensor = tensorfSentence(inp_lang, pair[0]), tensorfSentence(op_lang, pair[1])\n",
        "  return (inpTensor, target_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcRmH4DE1uEr"
      },
      "source": [
        "### NN Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtdTsj0qzFuB"
      },
      "outputs": [],
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "def train(inpTensor, target_tensor, encoder, decoder, encoderOptimizer, decoderOptimizer, criterion, max_length=MX_LENGTH):\n",
        "  encoderHdn = encoder.initHidden()\n",
        "\n",
        "  encoderOptimizer.zero_grad()\n",
        "  decoderOptimizer.zero_grad()\n",
        "  input_length = inpTensor.size(0)\n",
        "  target_length = target_tensor.size(0)\n",
        "  encoderOutputs = torch.zeros(max_length, encoder.hdnSize, device=cuda)\n",
        "  loss = 0\n",
        "\n",
        "  for ei in range(input_length):\n",
        "    encoder_output, encoderHdn = encoder(\n",
        "      inpTensor[ei], encoderHdn)\n",
        "    encoderOutputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "  decoder_input = torch.tensor([[SOS_tkn]], device=cuda)\n",
        "  decoder_hidden = encoderHdn\n",
        "  use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "  if use_teacher_forcing:\n",
        "    for di in range(target_length):\n",
        "      decoderOpt, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoderOutputs)\n",
        "      loss += criterion(decoderOpt, target_tensor[di])\n",
        "      decoder_input = target_tensor[di]\n",
        "  else:\n",
        "    for di in range(target_length):\n",
        "      decoderOpt, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoderOutputs)\n",
        "      topv, topi = decoderOpt.topk(1)\n",
        "      decoder_input = topi.squeeze().detach()\n",
        "\n",
        "      loss += criterion(decoderOpt, target_tensor[di])\n",
        "      if decoder_input.item() == EOS_tkn:\n",
        "        break\n",
        "  loss.backward()\n",
        "\n",
        "  encoderOptimizer.step()\n",
        "  decoderOptimizer.step()\n",
        "\n",
        "  return loss.item() / target_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laJv_pY2zVkX"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcv3oKduzZIj"
      },
      "outputs": [],
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0\n",
        "    plotLossTotal = 0\n",
        "\n",
        "    encoderOptimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoderOptimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        inpTensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(inpTensor, target_tensor, encoder,\n",
        "                     decoder, encoderOptimizer, decoderOptimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plotLossTotal += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plotLossTotal / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plotLossTotal = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-qRZZhkzk3I"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "  plt.figure()\n",
        "  fig, ax = plt.subplots()\n",
        "  # this locator puts ticks at regular intervals\n",
        "  loc = ticker.MultipleLocator(base=0.2)\n",
        "  ax.yaxis.set_major_locator(loc)\n",
        "  plt.plot(points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2OUFhCD1yaS"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ck_N2a9hzoxz"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MX_LENGTH):\n",
        "  with torch.no_grad():\n",
        "    inpTensor = tensorfSentence(inp_lang, sentence)\n",
        "    input_length = inpTensor.size()[0]\n",
        "    encoderHdn = encoder.initHidden()\n",
        "\n",
        "    encoderOutputs = torch.zeros(max_length, encoder.hdnSize, device=cuda)\n",
        "\n",
        "    for ei in range(input_length):\n",
        "      encoder_output, encoderHdn = encoder(inpTensor[ei],\n",
        "                                                encoderHdn)\n",
        "      encoderOutputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_tkn]], device=cuda) # SOS\n",
        "\n",
        "    decoder_hidden = encoderHdn\n",
        "\n",
        "    decoded_words = []\n",
        "    decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "    for di in range(max_length):\n",
        "      decoderOpt, decoder_hidden, decoder_attention = decoder(\n",
        "        decoder_input, decoder_hidden, encoderOutputs)\n",
        "      decoder_attentions[di] = decoder_attention.data\n",
        "      topv, topi = decoderOpt.data.topk(1)\n",
        "      if topi.item() == EOS_tkn:\n",
        "        decoded_words.append('<EOS>')\n",
        "        break\n",
        "      else:\n",
        "        decoded_words.append(op_lang.indexToword[topi.item()])\n",
        "\n",
        "      decoder_input = topi.squeeze().detach()\n",
        "\n",
        "    return decoded_words, decoder_attentions[:di + 1]\n",
        "\n",
        "def randomevaluation(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMn8EIw_OKLE",
        "outputId": "ce83575e-a10c-4cbc-8550-04c8215aad46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3m 17s (- 29m 40s) (10000 10%) 4.3229\n",
            "6m 39s (- 26m 36s) (20000 20%) 3.5987\n",
            "9m 47s (- 22m 51s) (30000 30%) 3.2527\n",
            "12m 52s (- 19m 18s) (40000 40%) 3.0135\n",
            "15m 57s (- 15m 57s) (50000 50%) 2.8800\n",
            "18m 59s (- 12m 39s) (60000 60%) 2.7143\n",
            "22m 4s (- 9m 27s) (70000 70%) 2.6357\n",
            "25m 9s (- 6m 17s) (80000 80%) 2.5725\n",
            "28m 18s (- 3m 8s) (90000 90%) 2.4868\n",
            "31m 24s (- 0m 0s) (100000 100%) 2.4081\n"
          ]
        }
      ],
      "source": [
        "hdnSize = 256\n",
        "encoder1 = EncoderRNN(inp_lang.min_words, hdnSize).to(cuda)\n",
        "attn_decoder1 = AttnDecoderRNN(hdnSize, op_lang.min_words, dropout_p=0.1).to(cuda)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 100000, print_every=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6jhMi6mDNI-",
        "outputId": "0849dc41-a8e0-43ec-f129-1e79cb4e0aeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> preguntale lo que ha hecho .\n",
            "= ask her what she has done .\n",
            "< you ve what done done . <EOS>\n",
            "\n",
            "> no toco el oboe .\n",
            "= i don t play the oboe .\n",
            "< i won t play my . . <EOS>\n",
            "\n",
            ">  cuanto dinero tiene tom ?\n",
            "= how much money does tom have ?\n",
            "< how much did tom money ? <EOS>\n",
            "\n",
            "> es idea de tom .\n",
            "= it s tom s idea .\n",
            "< it s idea tom tom . <EOS>\n",
            "\n",
            "> tom no te vio .\n",
            "= tom didn t see you .\n",
            "< tom didn t get you . <EOS>\n",
            "\n",
            "> mira lo que esta haciendo mary .\n",
            "= look at what mary is doing .\n",
            "< i know mary this is mary . . <EOS>\n",
            "\n",
            ">  puedes ayudarme a levantar esto ?\n",
            "= can you help me lift this ?\n",
            "< can you help me this ? ? <EOS>\n",
            "\n",
            "> tom aseguro que habia visto un ovni .\n",
            "= tom claimed that he saw a ufo .\n",
            "< tom thought he had a a . . . <EOS>\n",
            "\n",
            "> me puedo esconder en cualquier lugar .\n",
            "= i can hide anywhere .\n",
            "< i can stay in place in place . <EOS>\n",
            "\n",
            "> a tom le esta yendo muy bien hoy .\n",
            "= tom is doing very well today .\n",
            "< tom will this a very good time . <EOS>\n",
            "\n",
            ">  que listo !\n",
            "= that s clever .\n",
            "< what a ! ! ! ! ! ! ! !\n",
            "\n",
            ">  te gusta el golf ?\n",
            "= do you like golf ?\n",
            "< do you like golf ? <EOS>\n",
            "\n",
            "> tom no fue honesto .\n",
            "= tom wasn t honest .\n",
            "< tom wasn t . . . <EOS>\n",
            "\n",
            "> sone acerca de ti .\n",
            "= i dreamed about you .\n",
            "< i about about you you . <EOS>\n",
            "\n",
            "> hable despacio por favor .\n",
            "= speak slowly please .\n",
            "< please sit down . <EOS>\n",
            "\n",
            "> hemos sido descubiertos .\n",
            "= we ve been discovered .\n",
            "< we have been we . <EOS>\n",
            "\n",
            "> considerenme su amigo .\n",
            "= consider me your friend .\n",
            "< i friend her friend . <EOS>\n",
            "\n",
            "> no conozco a ninguna de las dos chicas .\n",
            "= i don t know either girl .\n",
            "< i don t know any of both . . .\n",
            "\n",
            "> nunca he visto un arco iris .\n",
            "= i ve never seen a rainbow .\n",
            "< i ve never seen a beautiful . . <EOS>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "randomevaluation(encoder1, attn_decoder1)\n",
        "\n",
        "for i in range(5000, 50000, 5000):\n",
        "  pair = pairs[i]\n",
        "  print('>', pair[0])\n",
        "  print('=', pair[1])\n",
        "  output_words, attentions = evaluate(encoder1, attn_decoder1, pair[0])\n",
        "  output_sentence = ' '.join(output_words)\n",
        "  print('<', output_sentence)\n",
        "  print('')\n",
        "\n",
        "def translate(input_sentence):\n",
        "    output_words, attentions = evaluate(encoder1, attn_decoder1, input_sentence)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPM4I4bbw6Xc"
      },
      "outputs": [],
      "source": [
        "def translate(input_sentence):\n",
        "    output_words, attentions = evaluate(encoder1, attn_decoder1, input_sentence)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUPDEHeREBrr"
      },
      "source": [
        "# Translating the sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saHFixefDTzB",
        "outputId": "c80bc237-4c5d-4171-e4d8-1169634ef361"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = ella llevaba un bonito sombrero\n",
            "output = she have a red on time . <EOS>\n"
          ]
        }
      ],
      "source": [
        "translate('ella llevaba un bonito sombrero')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSGVsmWVDbFH",
        "outputId": "fac97622-0707-401a-ec74-cf7f1f3d39ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = disfruta del espectaculo\n",
            "output = let s about your right ? <EOS>\n"
          ]
        }
      ],
      "source": [
        "translate('disfruta del espectaculo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI2pjagxDiZZ",
        "outputId": "30c82765-236d-4571-f9b9-a9973683c7da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = como estas\n",
            "output = you re know how <EOS>\n"
          ]
        }
      ],
      "source": [
        "translate('como estas')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgppACsJDttK",
        "outputId": "01da47a0-6a96-4e73-b14a-dcedafcfb735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = soy buena\n",
            "output = i m good at good <EOS>\n"
          ]
        }
      ],
      "source": [
        "translate('soy buena')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65djO91xD2gQ",
        "outputId": "58baabd4-ae66-43d6-9c96-41ee145bbde3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = soy una gran persona\n",
            "output = i m a good person . <EOS>\n"
          ]
        }
      ],
      "source": [
        "translate('soy una gran persona')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}